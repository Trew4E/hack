# The Personal Career Navigator

> **One agent. Two LLM calls. A complete career planning system.**

An AI-powered career co-pilot that analyzes a student's profile, identifies skill gaps against their dream role, generates a personalized 30-day learning roadmap with a flagship project, and adapts it in real-time when life happens.

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- [Ollama](https://ollama.ai) (runs locally, free & unlimited)

### Backend Setup
```bash
cd backend
pip install -r requirements.txt

# Pull the local model (one-time ~4.7GB download)
ollama pull mistral:7b

# Start the server
python -m uvicorn main:app --reload --port 8000
```

### Frontend
No build step needed! Just open in your browser:
```
frontend/index.html
```

---

## ğŸ§  How It Works

```
Resume (text or PDF) + Dream Role  â†’  Career Brain Agent

  Call 1: Skills + Gaps + 30-Day Roadmap
  Call 2: Flagship Project (uses gaps from Call 1)

  Optional: GitHub profile enrichment

Progress Update  â†’  Adaptation Call  â†’  Re-planned Roadmap
```

**LLM Fallback Chain:**
1. **Ollama** (local, free) â€” `mistral:7b` on GPU
2. **Mock data** (pre-built responses) â€” demo never crashes

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **PDF Resume Upload** | Upload a PDF resume â€” text is extracted automatically |
| **Custom Roles** | Type any dream role, not limited to presets |
| **GitHub Integration** | Optional GitHub username enriches the analysis with real coding data |
| **Two-Call Architecture** | Splits generation for reliable output from smaller models |
| **Post-Processing** | Backend fills missing fields so results are always complete |
| **Adaptive Re-Planning** | Simulate missed days â€” AI re-plans the remaining roadmap |

---

## ğŸ“‚ Project Structure

```
hack/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app, endpoints + post-processing
â”‚   â”œâ”€â”€ gemini_service.py    # Ollama LLM integration + fallback
â”‚   â”œâ”€â”€ prompts.py           # 3 prompt templates (roadmap, project, adapt)
â”‚   â”œâ”€â”€ models.py            # Pydantic request/response schemas
â”‚   â”œâ”€â”€ pdf_service.py       # PDF text extraction (PyPDF2)
â”‚   â”œâ”€â”€ github_service.py    # GitHub API integration + caching
â”‚   â”œâ”€â”€ mock_data.py         # Pre-built demo fallback data
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ test_github_service.py
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ roles.json       # 8 pre-defined dream roles
â”‚       â””â”€â”€ sample_resume.txt
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html           # Single-file UI (HTML + CSS + JS)
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ DEMO_SCRIPT.md
â””â”€â”€ README.md
```

---

## ğŸ— Tech Stack

| Layer | Tool | Why |
|-------|------|-----|
| LLM | Ollama + Mistral 7B (local) | Free, unlimited, no API key needed |
| Backend | FastAPI | Async, auto-docs, Pydantic validation |
| PDF Parsing | PyPDF2 | Extract text from uploaded resumes |
| GitHub API | REST + caching | Optional profile enrichment |
| Frontend | Single HTML file | Zero dependencies, no build step |
| Styling | Vanilla CSS | Dark mode, glassmorphism |

---

## âš™ï¸ Configuration

Set environment variables in `backend/.env`:
```bash
# Optional: Change Ollama model (default: mistral:7b)
OLLAMA_MODEL=mistral:7b

# Optional: GitHub token for higher API rate limits
GITHUB_TOKEN=ghp_your_token_here
```

---

## ğŸ¯ Demo Flow (5 minutes)

1. Paste resume text **or upload a PDF**
2. Select a dream role **or type a custom one**
3. Optionally enter a GitHub username
4. Click generate â†’ animated agent reasoning steps
5. Results: Skills â†’ Gaps â†’ 30-day Roadmap â†’ Flagship Project
6. Click "Simulate: Missed 7 Days" â†’ AI re-plans in real-time

---

## ğŸ“„ License

MIT â€” Built for hackathon demonstration.
